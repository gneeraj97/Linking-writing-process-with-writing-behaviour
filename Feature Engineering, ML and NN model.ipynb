{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88a6e3dd-5bd3-433e-84b1-24f6a852e4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be1a2b6-e9fb-4db2-bd20-cac4945243f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"train_scores.csv\")\n",
    "train = pd.read_csv(\"train_logs.csv\")\n",
    "train[\"activity2\"] = train['activity'].apply(lambda row: 'Move' if 'Move' in row else row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30349d46-74f2-4fe6-876a-779ccc70d0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final_word_count(df):\n",
    "    return df.iloc[-1]['word_count']\n",
    "\n",
    "def add_features(df):\n",
    "    df[\"unsurity\"] = ((df['text_change'].str.len() > 50) & (df['activity2']==\"Remove/Cut\")).apply(lambda x: int(x))\n",
    "    df[\"structural_change\"] = ((df['text_change'].str.len() > 50) & (df['activity2']==\"Replace\")).apply(lambda x: int(x))\n",
    "    df[\"long_paste\"] = ((df['text_change'].str.len() > 50) & (df['activity2']==\"Paste\")).apply(lambda x: int(x))\n",
    "    df[\"unproductive_time\"] = (train['activity2'] == \"Nonproduction\")*train['action_time']\n",
    "    df[\"external_help\"] = ((df['word_count'] < 10) & (df['activity2']==\"Paste\")).apply(lambda x: int(x))\n",
    "    df[\"pasted_words_number\"] = (train['activity2'] == \"Paste\")*train['text_change'].str.split().apply(len)\n",
    "    df[\"large_changes\"] = (df['text_change'].str.len() > 50).apply(lambda x: int(x))\n",
    "    return df\n",
    "\n",
    "def drop_unrelated_features(df, feat):\n",
    "    df = df.drop(feat, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17ba836-67eb-4e98-82b2-656811293939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>down_time</th>\n",
       "      <th>up_time</th>\n",
       "      <th>action_time</th>\n",
       "      <th>activity</th>\n",
       "      <th>down_event</th>\n",
       "      <th>up_event</th>\n",
       "      <th>text_change</th>\n",
       "      <th>cursor_position</th>\n",
       "      <th>word_count</th>\n",
       "      <th>activity2</th>\n",
       "      <th>unsurity</th>\n",
       "      <th>structural_change</th>\n",
       "      <th>long_paste</th>\n",
       "      <th>unproductive_time</th>\n",
       "      <th>external_help</th>\n",
       "      <th>pasted_words_number</th>\n",
       "      <th>large_changes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>1</td>\n",
       "      <td>4526</td>\n",
       "      <td>4557</td>\n",
       "      <td>31</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>NoChange</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2</td>\n",
       "      <td>4558</td>\n",
       "      <td>4962</td>\n",
       "      <td>404</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>Leftclick</td>\n",
       "      <td>NoChange</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>3</td>\n",
       "      <td>106571</td>\n",
       "      <td>106571</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>Shift</td>\n",
       "      <td>Shift</td>\n",
       "      <td>NoChange</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nonproduction</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>4</td>\n",
       "      <td>106686</td>\n",
       "      <td>106777</td>\n",
       "      <td>91</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Input</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>5</td>\n",
       "      <td>107196</td>\n",
       "      <td>107323</td>\n",
       "      <td>127</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Input</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  event_id  down_time  up_time  action_time       activity  \\\n",
       "0  001519c8         1       4526     4557           31  Nonproduction   \n",
       "1  001519c8         2       4558     4962          404  Nonproduction   \n",
       "2  001519c8         3     106571   106571            0  Nonproduction   \n",
       "3  001519c8         4     106686   106777           91          Input   \n",
       "4  001519c8         5     107196   107323          127          Input   \n",
       "\n",
       "  down_event   up_event text_change  cursor_position  word_count  \\\n",
       "0  Leftclick  Leftclick    NoChange                0           0   \n",
       "1  Leftclick  Leftclick    NoChange                0           0   \n",
       "2      Shift      Shift    NoChange                0           0   \n",
       "3          q          q           q                1           1   \n",
       "4          q          q           q                2           1   \n",
       "\n",
       "       activity2  unsurity  structural_change  long_paste  unproductive_time  \\\n",
       "0  Nonproduction         0                  0           0                 31   \n",
       "1  Nonproduction         0                  0           0                404   \n",
       "2  Nonproduction         0                  0           0                  0   \n",
       "3          Input         0                  0           0                  0   \n",
       "4          Input         0                  0           0                  0   \n",
       "\n",
       "   external_help  pasted_words_number  large_changes  \n",
       "0              0                    0              0  \n",
       "1              0                    0              0  \n",
       "2              0                    0              0  \n",
       "3              0                    0              0  \n",
       "4              0                    0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data = train.groupby(['id', \"up_event\"])\n",
    "down = grouped_data[\"event_id\"].count()\n",
    "pivot = pd.pivot_table(data = down.reset_index(), index = \"id\", columns = \"up_event\", values = \"event_id\" ).fillna(0)\n",
    "train = add_features(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f8f5d5-b02d-47e5-8fe4-2e69addc66e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_data = train.groupby('id')\n",
    "user = grouped_data.apply(lambda df: pd.Series({\n",
    "    'Final Word Count': final_word_count(df)\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e0b896-8999-414f-8767-3f9bdb2cd3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(train['activity2'], prefix='activity').astype(int)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "train = pd.concat([train, one_hot_encoded], axis=1)\n",
    "train = train.drop(\"activity2\", axis = 1)\n",
    "train = train.drop(\"up_event\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df9fd5a4-9266-4db9-a1d9-a465850077ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>action_time</th>\n",
       "      <th>unsurity</th>\n",
       "      <th>structural_change</th>\n",
       "      <th>long_paste</th>\n",
       "      <th>unproductive_time</th>\n",
       "      <th>external_help</th>\n",
       "      <th>pasted_words_number</th>\n",
       "      <th>large_changes</th>\n",
       "      <th>activity_Input</th>\n",
       "      <th>activity_Move</th>\n",
       "      <th>activity_Nonproduction</th>\n",
       "      <th>activity_Paste</th>\n",
       "      <th>activity_Remove/Cut</th>\n",
       "      <th>activity_Replace</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001519c8</th>\n",
       "      <td>2557</td>\n",
       "      <td>297243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>417</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0022f953</th>\n",
       "      <td>2454</td>\n",
       "      <td>275391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1938</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0042269b</th>\n",
       "      <td>4136</td>\n",
       "      <td>421201</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3515</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>439</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0059420b</th>\n",
       "      <td>1556</td>\n",
       "      <td>189596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3062</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0075873a</th>\n",
       "      <td>2531</td>\n",
       "      <td>313702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          event_id  action_time  unsurity  structural_change  long_paste  \\\n",
       "id                                                                         \n",
       "001519c8      2557       297243         0                  0           0   \n",
       "0022f953      2454       275391         0                  0           0   \n",
       "0042269b      4136       421201         1                  4           0   \n",
       "0059420b      1556       189596         0                  0           0   \n",
       "0075873a      2531       313702         0                  0           0   \n",
       "\n",
       "          unproductive_time  external_help  pasted_words_number  \\\n",
       "id                                                                \n",
       "001519c8              18506              0                    0   \n",
       "0022f953              13781              0                    0   \n",
       "0042269b              33951              0                    0   \n",
       "0059420b               3062              0                    1   \n",
       "0075873a               6988              0                    0   \n",
       "\n",
       "          large_changes  activity_Input  activity_Move  \\\n",
       "id                                                       \n",
       "001519c8              0            2010              3   \n",
       "0022f953              0            1938              0   \n",
       "0042269b              5            3515              0   \n",
       "0059420b              0            1304              0   \n",
       "0075873a              0            1942              0   \n",
       "\n",
       "          activity_Nonproduction  activity_Paste  activity_Remove/Cut  \\\n",
       "id                                                                      \n",
       "001519c8                     120               0                  417   \n",
       "0022f953                     254               1                  260   \n",
       "0042269b                     175               0                  439   \n",
       "0059420b                      99               1                  151   \n",
       "0075873a                      72               0                  517   \n",
       "\n",
       "          activity_Replace  \n",
       "id                          \n",
       "001519c8                 7  \n",
       "0022f953                 1  \n",
       "0042269b                 7  \n",
       "0059420b                 1  \n",
       "0075873a                 0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_columns = {\n",
    "    'event_id':'count',\n",
    "    'action_time': 'sum',\n",
    "    'unsurity': 'sum',\n",
    "    'structural_change': 'sum',\n",
    "    'long_paste': 'sum',\n",
    "    'unproductive_time': 'sum',\n",
    "    'external_help': 'sum',\n",
    "    'pasted_words_number': 'sum',\n",
    "    'large_changes': 'sum',\n",
    "    'activity_Input': 'sum',\n",
    "    'activity_Move': 'sum',\n",
    "    'activity_Nonproduction': 'sum',\n",
    "    'activity_Paste': 'sum',\n",
    "    'activity_Remove/Cut': 'sum',\n",
    "    'activity_Replace': 'sum'\n",
    "}\n",
    "user_level = train.groupby('id').agg(agg_columns)\n",
    "user_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2984b065-b41f-4d50-b176-79fb1d9d6d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data = pd.merge(user_level, pivot, on='id', how='inner')\n",
    "final_merge = pd.merge(merged_data, user, on='id', how='inner')\n",
    "final_merge = final_merge.reset_index()\n",
    "# final_merge.to_csv(\"train_final.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00443d14-cc7f-42a3-ba3d-7191b9348a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>action_time</th>\n",
       "      <th>unsurity</th>\n",
       "      <th>structural_change</th>\n",
       "      <th>long_paste</th>\n",
       "      <th>unproductive_time</th>\n",
       "      <th>external_help</th>\n",
       "      <th>pasted_words_number</th>\n",
       "      <th>large_changes</th>\n",
       "      <th>activity_Input</th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th>¡</th>\n",
       "      <th>¿</th>\n",
       "      <th>Â´</th>\n",
       "      <th>Ä±</th>\n",
       "      <th>Å</th>\n",
       "      <th>Ë</th>\n",
       "      <th>â</th>\n",
       "      <th>ä</th>\n",
       "      <th>Final Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2.471000e+03</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>2471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3401.820316</td>\n",
       "      <td>3.336675e+05</td>\n",
       "      <td>0.352084</td>\n",
       "      <td>0.163497</td>\n",
       "      <td>0.102388</td>\n",
       "      <td>17909.078106</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>5.253339</td>\n",
       "      <td>0.628895</td>\n",
       "      <td>2722.297046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>386.112100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1578.850387</td>\n",
       "      <td>1.575202e+05</td>\n",
       "      <td>0.887996</td>\n",
       "      <td>0.536878</td>\n",
       "      <td>0.424501</td>\n",
       "      <td>32568.430834</td>\n",
       "      <td>0.075129</td>\n",
       "      <td>42.045249</td>\n",
       "      <td>1.458841</td>\n",
       "      <td>1196.384644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.028444</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.142220</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.080468</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>171.773394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>262.000000</td>\n",
       "      <td>1.345200e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2193.500000</td>\n",
       "      <td>2.111480e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3993.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1786.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3082.000000</td>\n",
       "      <td>3.049510e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9308.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2477.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4301.000000</td>\n",
       "      <td>4.248140e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19685.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3397.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12876.000000</td>\n",
       "      <td>1.210508e+06</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>482115.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1326.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           event_id   action_time     unsurity  structural_change  \\\n",
       "count   2471.000000  2.471000e+03  2471.000000        2471.000000   \n",
       "mean    3401.820316  3.336675e+05     0.352084           0.163497   \n",
       "std     1578.850387  1.575202e+05     0.887996           0.536878   \n",
       "min      262.000000  1.345200e+04     0.000000           0.000000   \n",
       "25%     2193.500000  2.111480e+05     0.000000           0.000000   \n",
       "50%     3082.000000  3.049510e+05     0.000000           0.000000   \n",
       "75%     4301.000000  4.248140e+05     0.000000           0.000000   \n",
       "max    12876.000000  1.210508e+06     9.000000           6.000000   \n",
       "\n",
       "        long_paste  unproductive_time  external_help  pasted_words_number  \\\n",
       "count  2471.000000        2471.000000    2471.000000          2471.000000   \n",
       "mean      0.102388       17909.078106       0.004856             5.253339   \n",
       "std       0.424501       32568.430834       0.075129            42.045249   \n",
       "min       0.000000           6.000000       0.000000             0.000000   \n",
       "25%       0.000000        3993.000000       0.000000             0.000000   \n",
       "50%       0.000000        9308.000000       0.000000             0.000000   \n",
       "75%       0.000000       19685.500000       0.000000             0.000000   \n",
       "max       6.000000      482115.000000       2.000000          1016.000000   \n",
       "\n",
       "       large_changes  activity_Input  ...                        ¡  \\\n",
       "count    2471.000000     2471.000000  ...  2471.000000  2471.000000   \n",
       "mean        0.628895     2722.297046  ...     0.000405     0.000405   \n",
       "std         1.458841     1196.384644  ...     0.020117     0.020117   \n",
       "min         0.000000      230.000000  ...     0.000000     0.000000   \n",
       "25%         0.000000     1786.000000  ...     0.000000     0.000000   \n",
       "50%         0.000000     2477.000000  ...     0.000000     0.000000   \n",
       "75%         1.000000     3397.500000  ...     0.000000     0.000000   \n",
       "max        17.000000     9091.000000  ...     1.000000     1.000000   \n",
       "\n",
       "                 ¿           Â´           Ä±           Å           Ë  \\\n",
       "count  2471.000000  2471.000000  2471.000000  2471.000000  2471.000000   \n",
       "mean      0.000809     0.000405     0.004047     0.000405     0.000405   \n",
       "std       0.028444     0.020117     0.142220     0.020117     0.020117   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     5.000000     1.000000     1.000000   \n",
       "\n",
       "               â            ä  Final Word Count  \n",
       "count  2471.000000  2471.000000       2471.000000  \n",
       "mean      0.001619     0.000405        386.112100  \n",
       "std       0.080468     0.020117        171.773394  \n",
       "min       0.000000     0.000000         35.000000  \n",
       "25%       0.000000     0.000000        250.000000  \n",
       "50%       0.000000     0.000000        346.000000  \n",
       "75%       0.000000     0.000000        477.000000  \n",
       "max       4.000000     1.000000       1326.000000  \n",
       "\n",
       "[8 rows x 146 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merge.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4399435-a1b2-42c6-9158-8b51fe4d10ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed = final_merge.copy()\n",
    "col = final_merge.columns\n",
    "transformed[col[1:]] = final_merge[col[1:]].apply(lambda x: x.apply(lambda y: np.log1p(y)))\n",
    "# transformed.to_csv(\"transformed.csv\")\n",
    "\n",
    "# scores = pd.read_csv(\"train_scores.csv\")\n",
    "final_v1 = pd.merge(transformed, scores, on='id', how='inner')\n",
    "\n",
    "# final_v1.to_csv(\"Final_v1.csv\")\n",
    "x = transformed.drop(columns=[\"id\"])\n",
    "y = scores[\"score\"]\n",
    "\n",
    "# Split the data into training and testing sets (adjust the test_size parameter as needed)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.1, random_state=1\n",
    ")\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.1, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf3be88-f953-429a-837b-3c20602e2627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.30224046 0.14672836 0.07983854 0.05341544 0.0506591  0.03920866\n",
      " 0.03177747 0.02834841 0.02593465 0.01816751 0.01742956 0.01639316\n",
      " 0.01472954 0.01288028 0.01255977 0.0117721  0.01110459 0.0107669\n",
      " 0.00875303 0.00839945 0.00647699 0.0062563  0.00602025 0.00575026\n",
      " 0.00526908 0.00429347 0.0040662  0.00392673 0.00384198 0.00362141]\n",
      "Number of Components: 30\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA\n",
    "pca = PCA()\n",
    "xtrain_pca = pca.fit_transform(x_train)\n",
    "\n",
    "# Calculate the cumulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Determine the number of components to capture a specified variance threshold (e.g., 95%)\n",
    "variance_threshold = 0.95\n",
    "num_components = np.argmax(cumulative_explained_variance >= variance_threshold) + 1\n",
    "\n",
    "# Use the specified number of components\n",
    "pca = PCA(n_components=num_components)\n",
    "xtrain_pca = pca.fit_transform(x_train)\n",
    "xval_pca = pca.transform(x_val)\n",
    "xtest_pca = pca.transform(x_test)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "xtrain_pca_df = pd.DataFrame(data=xtrain_pca, columns=[f'PC{i}' for i in range(1, num_components + 1)])\n",
    "xval_pca_df = pd.DataFrame(data=xval_pca, columns=[f'PC{i}' for i in range(1, num_components + 1)])\n",
    "xtest_pca_df = pd.DataFrame(data=xtest_pca, columns=[f'PC{i}' for i in range(1, num_components + 1)])\n",
    "\n",
    "# Print the explained variance ratio and number of components\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Number of Components:\", num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f81fd5-b8f8-4193-b33c-ce1145282fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Set hyperparameters\n",
    "    model = GradientBoostingRegressor(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        min_samples_split=int(params['min_samples_split']),\n",
    "        min_samples_leaf=int(params['min_samples_leaf']),\n",
    "        subsample=params['subsample']\n",
    "    )\n",
    "\n",
    "    # Make predictions using cross-validation on the training set\n",
    "    predictions = cross_val_predict(model, xtrain_pca_df, y_train.values.flatten(), cv=5)\n",
    "\n",
    "    # Calculate RMSE (you can replace this with your own evaluation metric)\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, predictions))\n",
    "\n",
    "    # Return the value to be minimized (in this case, RMSE)\n",
    "    return rmse\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1)\n",
    "}\n",
    "\n",
    "# Specify the optimization algorithm (Tree-structured Parzen Estimator)\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "# Create Trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run the optimization\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe_algorithm,\n",
    "            trials=trials,\n",
    "            max_evals=100)  # You can adjust the number of evaluations\n",
    "\n",
    "\n",
    "print(\"Best Hyperparameters:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f5aa9-c705-4df0-8a9c-769b7a7104fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'n_estimators': int(best['n_estimators']),\n",
    "    'max_depth': int(best['max_depth']),\n",
    "    'min_samples_split': int(best['min_samples_split']),\n",
    "    'min_samples_leaf': int(best['min_samples_leaf']),\n",
    "    'subsample': best['subsample']\n",
    "}\n",
    "\n",
    "\n",
    "best_model = GradientBoostingRegressor(**best_params)\n",
    "best_model.fit(xtrain_pca_df, y_train.values.flatten())\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_model.predict(xtest_pca_df)\n",
    "\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b67ef-2636-473b-b27c-c799dc21bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Set hyperparameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        min_samples_split=int(params['min_samples_split']),\n",
    "        min_samples_leaf=int(params['min_samples_leaf']),\n",
    "        max_features=params['max_features'],\n",
    "        random_state=42  # Set a fixed random state for reproducibility\n",
    "    )\n",
    "\n",
    "    # Make predictions using cross-validation on the training set\n",
    "    predictions = cross_val_predict(model, xtrain_pca_df, y_train.values.flatten(), cv=5)\n",
    "\n",
    "    # Calculate RMSE (you can replace this with your own evaluation metric)\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, predictions))\n",
    "\n",
    "    # Return the value to be minimized (in this case, RMSE)\n",
    "    return rmse\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1),\n",
    "    'max_features': hp.uniform('max_features', 0.1, 1.0)\n",
    "}\n",
    "\n",
    "# Specify the optimization algorithm (Tree-structured Parzen Estimator)\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "# Create Trials object to store optimization results\n",
    "trials = Trials()\n",
    "\n",
    "# Run the optimization\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe_algorithm,\n",
    "            trials=trials,\n",
    "            max_evals=100)  # adjust the number of evaluations here\n",
    "\n",
    "\n",
    "print(\"Best Hyperparameters:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142f55d-c8e6-4b06-be8a-4eada722c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'n_estimators': int(best['n_estimators']),\n",
    "    'max_depth': int(best['max_depth']),\n",
    "    'min_samples_split': int(best['min_samples_split']),\n",
    "    'min_samples_leaf': int(best['min_samples_leaf']),\n",
    "    'max_features': best['max_features'],\n",
    "    'random_state': 42  # Set a fixed random state for reproducibility\n",
    "}\n",
    "\n",
    "\n",
    "best_model = RandomForestRegressor(**best_params)\n",
    "best_model.fit(xtrain_pca_df, y_train.values.flatten())\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_model.predict(xtest_pca_df)\n",
    "\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158615a-32ff-4d64-99df-bed06da6df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLPRegression, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 64)\n",
    "        self.fc4 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(xtrain_pca_df.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(xval_pca_df.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "\n",
    "# Define the model\n",
    "input_size = xtrain_pca_df.shape[1]  \n",
    "output_size = 1  \n",
    "model = MLPRegression(input_size, output_size)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # adjust the learning rate here\n",
    "\n",
    "# Create a DataLoader for batch training\n",
    "batch_size = 64  \n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "epoch_list = []\n",
    "training_error = []\n",
    "validation_error = []\n",
    "\n",
    "num_epochs = 200  # adjust the number of epochs here\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    epoch_list.append(epoch)\n",
    "    \n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.sqrt(criterion(outputs, targets))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += torch.sqrt(criterion(outputs, targets))\n",
    "\n",
    "    average_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_loss:.4f} | Validation Loss: {average_val_loss:.4f}')\n",
    "    training_error.append(average_loss)\n",
    "    validation_error.append(average_val_loss)\n",
    "    \n",
    "plt.plot(epoch_list, training_error, label='Training Loss',linestyle='-')\n",
    "plt.plot(epoch_list, validation_error, label='Validation Loss',linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Root Mean Squared Error')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "print(min(validation_error))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8b24d-ecb9-48cb-b1cd-954b20d4f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(xtest_pca_df.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "\n",
    "# Calculate the test loss\n",
    "test_loss = torch.sqrt(criterion(test_outputs, y_test_tensor))\n",
    "print(\"Test RMSE:\", test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c61233-57dc-45e2-9a5a-18f44b688be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
